{
  "$schema": "https://opencode.ai/config.json",
  "permission": {
    "*": "allow",
    "doom_loop": "deny"
  },
  "provider": {
    "llmproxy": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LLM Proxy",
      "options": {
        "baseURL": "https://llmapi.llm.blazelight.dev/v1",
        "apiKey": "sk-hunter2"
      },
      "models": {
        "alias/cheapest": {"name": "LLM Model", "limit": {"context": 200000, "output": 64000}}
      }
    }
  }
}
