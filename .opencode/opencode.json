{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "llmproxy": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LLM Proxy",
      "options": {
        "baseURL": "{env:LLM_PROXY_URL}",
        "apiKey": "{env:LLM_PROXY_API_KEY}"
      },
      "models": {
        "{env:LLM_MODEL}": {
          "name": "LLM Model",
          "limit": {
            "context": 200000,
            "output": 64000
          }
        }
      }
    }
  }
}
